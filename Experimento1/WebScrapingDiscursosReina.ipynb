{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScrapingDiscursosReina.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88IZQL4CtsnP"
      },
      "source": [
        "# Obtención de discursos de la reina de Inglaterra desde la página web de la casa real británica. Se realiza mediante *web scraping*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfvsfVtsudGQ"
      },
      "source": [
        "Obtenemos los enlaces a cada discurso:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIv_8BmMdrf2"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "\n",
        "base_enlaces = 'https://www.royal.uk' \n",
        "base_paginas = 'https://www.royal.uk/speeches?text=&mrf=2&date[min][date]=01/06/1909&date[max][date]=8/10/2020&id=&page='\n",
        "PAGINAS = 31 # Número de paginas donde hay enlaces a discursos\n",
        " \n",
        "# Obtener los enlaces de las paginas\n",
        "def url_to_transcript(url):\n",
        "    page = requests.get(url).text\n",
        "    soup = BeautifulSoup(page, \"lxml\")\n",
        "    enlaces = []\n",
        "    for title in soup.find_all(class_=\"listing\"):\n",
        "        for a in title.find_all('a', href=True):\n",
        "            enlace_discurso = base_enlaces + a['href']\n",
        "            enlaces.append(enlace_discurso) if enlace_discurso not in enlaces else enlaces\n",
        "    return enlaces\n",
        "\n",
        "urls = []\n",
        "paginas = [str(i) for i in range(PAGINAS)]\n",
        "for pagina in paginas:\n",
        "    urls.append(base_paginas + pagina)\n",
        " \n",
        "# Recorrer las URLs y obtener los enlaces página a página\n",
        "enlaces_matrix = [url_to_transcript(u) for u in urls]\n",
        "# Obtenemos un vector con todos los enlaces juntos\n",
        "enlaces = [enlace for vector_enlaces in enlaces_matrix for enlace in vector_enlaces]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IifkD7yumD5"
      },
      "source": [
        "Obtenemos el texto de cada enlace, con el formato querido:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REUMUOfMPgGV"
      },
      "source": [
        "def url_get_text(url):\n",
        "    # Obtener los textos de los discursos.\n",
        "    print('URL',url)\n",
        "    text=\"\"\n",
        "    title=\"\"\n",
        "    try:\n",
        "        page = requests.get(url).text\n",
        "        soup = BeautifulSoup(page, \"lxml\")\n",
        "        title = [p.text for p in soup.find_all(id=\"page-title-wrapper\")]\n",
        "        # BORRAMOS LA CITA EXTRAIDA DEL PROPIO DISCURSO\n",
        "        if soup.find(\"blockquote\") is not None:\n",
        "          soup.find('blockquote').decompose()\n",
        "        # BORRAMOS EL PARRAFO DE COMPARTIR\n",
        "        soup.find('div', class_=\"tbm-share-links share\").decompose()\n",
        "        # Obtenemos los demás párrafos (los que nos interesan)\n",
        "        text = [p.text for p in soup.find(class_=\"content\").find_all('p')]\n",
        "    except Exception:\n",
        "        print('ERROR, no se pudo abrir la pagina.')\n",
        "        return '', ''\n",
        "    return title, text\n",
        "\n",
        "# Recorrer las URLs y obtener los textos\n",
        "textos=[]\n",
        "titulos=[]\n",
        "num_discursos = len(enlaces)\n",
        "for i in range(len(enlaces)):\n",
        "    enlace_discurso = enlaces[i]\n",
        "    titulo, texto = url_get_text(enlace_discurso)\n",
        "    if titulo != '':\n",
        "      titulos.append(titulo)\n",
        "      textos.append(texto)\n",
        "    else:\n",
        "      num_discursos = num_discursos - 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjQIlA26vDIJ"
      },
      "source": [
        "Añadimos el texto a una cadena continua con saltos de línea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjaCJMSwlaTv"
      },
      "source": [
        "cad = ''\n",
        "for texto in textos[2]:\n",
        "    cad=cad + '\\n' + texto\n",
        "cad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQrPClagvQzF"
      },
      "source": [
        "Eliminamos los saltos de línea de los títulos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZSIBFdTaRP1"
      },
      "source": [
        "# Eliminamos los saltos de línea de los títulos\n",
        "for i in range(len(titulos)):\n",
        "  titulos[i][0] = ' '.join(titulos[i][0].split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PWFWqSjvYSy"
      },
      "source": [
        "Creamos la carpeta en Drive donde guardar los ficheros con los discursos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD-D24e_Qby1"
      },
      "source": [
        "## Creamos un directorio y nombramos los archivos por año\n",
        "!rm -r /content/drive/My\\ Drive/discursos_reina\n",
        "!mkdir -p ./drive/My\\ Drive/discursos_reina\n",
        "\n",
        "for i in range(num_discursos):\n",
        "    with open(\"./drive/My Drive/discursos_reina/\" + str(i) + '-' + titulos[i][0] + \".txt\", \"w\") as file:\n",
        "        cad=''\n",
        "        for texto in textos[i]:\n",
        "                cad=cad + '\\n' + texto\n",
        "        file.write(cad)\n",
        "        file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}